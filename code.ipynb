{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Research in Neural Networks and SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mnist_reader\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = mnist_reader.load_mnist('fashion', kind='train')\n",
    "X_test, y_test = mnist_reader.load_mnist('fashion', kind='t10k')\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the samples but the ones with labels 5 and 7\n",
    "\n",
    "mask_train = (y_train == 5) | (y_train ==7)\n",
    "X_train = X_train[mask_train]\n",
    "y_train = y_train[mask_train]\n",
    "\n",
    "mask_test = (y_test == 5) | (y_test ==7)\n",
    "X_test = X_test[mask_test]\n",
    "y_test = y_test[mask_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing Label 5 and 7 to 0 and 1 respectively\n",
    "\n",
    "y_train = np.where(y_train == 5, 0, 1)\n",
    "y_test = np.where(y_test == 5, 0, 1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing each feature vector to its unit form\n",
    "\n",
    "epsilon = 1e-10\n",
    "\n",
    "norm_train = np.linalg.norm(X_train, axis=1, keepdims=True)\n",
    "norm_train = np.where(norm_train == 0, epsilon, norm_train)\n",
    "X_train = X_train/norm_train\n",
    "\n",
    "norm_test = np.linalg.norm(X_test, axis=1, keepdims=True)\n",
    "norm_test = np.where(norm_test == 0, epsilon, norm_test)\n",
    "X_test = X_test/norm_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the current data set to get a validation set\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = sk.model_selection.train_test_split(X_train, y_train, train_size = 0.5, test_size=0.2, random_state = 1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding noise to the data set\n",
    "\n",
    "noise_mask_train = np.random.rand(len(y_train)) < 0.2\n",
    "y_train_noisy = np.copy(y_train)\n",
    "y_train_noisy[noise_mask_train] = np.where(y_train_noisy[noise_mask_train] == 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold cross-validation training function\n",
    "\n",
    "def k_fold_training(x, y, model, k):\n",
    "\n",
    "    fold_size = len(x)//k\n",
    "\n",
    "    indices = np.arange(len(x))\n",
    "\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for i in range(k):\n",
    "        testing_indices = indices[i*fold_size : (i+1)*fold_size]\n",
    "        training_indices = np.concatenate((indices[:i*fold_size], indices[(i+1)*fold_size:]))\n",
    "\n",
    "        x_training, x_testing = x[training_indices], x[testing_indices]\n",
    "        y_training, y_testing = y[training_indices], y[testing_indices]\n",
    "\n",
    "        model.fit(x_training, y_training)\n",
    "\n",
    "        accuracy = model.score(x_training, y_training)\n",
    "        scores.append(accuracy)\n",
    "        \n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train svm from a list of C or Gamma values\n",
    "\n",
    "def train_svm(c_values = None, gamma_values = None, kernel:str = 'linear'):\n",
    "\n",
    "    training_scores = []\n",
    "    validation_scores = []\n",
    "\n",
    "    if kernel == 'linear':\n",
    "        for c in c_values:\n",
    "            linear_svm = sk.svm.SVC(kernel = kernel, C = c)\n",
    "            linear_svm.fit(X_train, y_train_noisy)\n",
    "            \n",
    "            validation_scores.append(linear_svm.score(X_validation, y_validation))\n",
    "            training_scores.append(linear_svm.score(X_train, y_train))\n",
    "\n",
    "            print(f'Scores for C={c} already processed')\n",
    "\n",
    "    elif (kernel == 'gaussian') or (kernel == 'rbf'):\n",
    "        for gamma in gamma_values:\n",
    "            gaussian_svm = sk.svm.SVC(kernel = kernel, gamma = gamma)\n",
    "            gaussian_svm.fit(X_train, y_train_noisy)\n",
    "            \n",
    "            validation_scores.append(gaussian_svm.score(X_validation, y_validation))\n",
    "            training_scores.append(gaussian_svm.score(X_train, y_train))\n",
    "\n",
    "            print(f'Scores for Gamma={gamma} already processed')\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported kernel. Please use 'linear' or 'gaussian'.\")\n",
    "\n",
    "    return training_scores, validation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuction that uses \"k_fold_training\" to compare different values of C or Gamma\n",
    "\n",
    "def cross_validation(models_list):\n",
    "    models_scores = []\n",
    "    count = 0\n",
    "    for model in models_list:\n",
    "        models_scores.append(k_fold_training(X_train, y_train_noisy, model, 5))\n",
    "        count += 1\n",
    "        print(f'Model number {count} processed')\n",
    "    return models_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing C or Gamma values\n",
    "\n",
    "def test_svm(c_values = None, gamma_values = None, kernel:str = 'linear'):\n",
    "\n",
    "    X_combined = np.vstack((X_train, X_validation))\n",
    "    y_combined = np.concatenate((y_train, y_validation), axis=0)\n",
    "\n",
    "    \n",
    "    training_scores = []\n",
    "    test_scores = []\n",
    "\n",
    "    if kernel == 'linear':\n",
    "        for c in c_values:\n",
    "            linear_svm = sk.svm.SVC(kernel = kernel, C = c)\n",
    "            linear_svm.fit(X_combined, y_combined)\n",
    "\n",
    "            test_scores.append(linear_svm.score(X_test, y_test))\n",
    "            training_scores.append(linear_svm.score(X_train, y_train))\n",
    "            \n",
    "            \n",
    "\n",
    "            print(f'Scores for C={c} were processed')\n",
    "\n",
    "    elif (kernel == 'gaussian') or (kernel == 'rbf'):\n",
    "        for gamma in gamma_values:\n",
    "            gaussian_svm = sk.svm.SVC(kernel = kernel, gamma = gamma)\n",
    "            gaussian_svm.fit(X_combined, y_combined)\n",
    "            \n",
    "            test_scores.append(gaussian_svm.score(X_test, y_test))\n",
    "            training_scores.append(gaussian_svm.score(X_train, y_train))\n",
    "\n",
    "            print(f'Scores for Gamma={gamma} were processed')\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported kernel. Please use 'linear' or 'gaussian'.\")\n",
    "\n",
    "    return training_scores, test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments and Analysis\n",
    "**SVM with linear kernel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the list of C values to be tested\n",
    "\n",
    "C_values = [0.001]\n",
    "for val in range(1,10):\n",
    "    C_values.append(C_values[0]*(4**val))\n",
    "    \n",
    "print(C_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training SVMs with the list of Cs\n",
    "\n",
    "training_scores, validation_scores = train_svm(C_values, kernel = 'linear')\n",
    "print (training_scores)\n",
    "print (validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the error in training and validation sets \n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(C_values, training_scores, label='Training Score', marker='o', linestyle='-', color='blue')\n",
    "    \n",
    "plt.plot(C_values, validation_scores, label='Validation Score', marker='o', linestyle='--', color='red')\n",
    "    \n",
    "\n",
    "plt.xlabel('C Values')\n",
    "plt.ylabel('Score')\n",
    "plt.title('SVM Scores vs C Values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using K-fold training for the best 5 C values\n",
    "\n",
    "best_Cs = [0.512, 1.024, 2.048, 4.096, 8.192]\n",
    "models = []\n",
    "for c in best_Cs:\n",
    "    linear_svm = sk.svm.SVC(kernel = 'linear', C = c)\n",
    "    models.append(linear_svm)\n",
    "    \n",
    "models_scores = cross_validation(models)\n",
    "\n",
    "print(models_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the error in training and test sets\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(best_Cs, models_scores, label='Training Score', marker='o', linestyle='-', color='blue')    \n",
    "\n",
    "plt.xlabel('C Values')\n",
    "plt.ylabel('Score')\n",
    "plt.title('SVM Scores vs C Values Using K-fold Cross-Validation')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Values of C\n",
    "\n",
    "best_Cs_test = [0.512, 1.024, 2.048, 4.096, 8.192, 16.384]\n",
    "\n",
    "training_scores, test_scores = test_svm(c_values = best_Cs_test, kernel = 'linear')\n",
    "\n",
    "print (training_scores, test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(best_Cs_test, training_scores, label='Training Score', marker='o', linestyle='-', color='blue')\n",
    "plt.plot(best_Cs_test, test_scores, label='Testing Score', marker='o', linestyle='--', color='red')    \n",
    "\n",
    "\n",
    "plt.xlabel('C Values')\n",
    "plt.ylabel('Score')\n",
    "plt.title('SVM Scores vs C Values in the Full Training and Test Sets')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM with gaussian kernels**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
