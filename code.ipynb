{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Research in Neural Networks and SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mnist_reader\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = mnist_reader.load_mnist('fashion', kind='train')\n",
    "X_test, y_test = mnist_reader.load_mnist('fashion', kind='t10k')\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the samples but the ones with labels 5 and 7\n",
    "\n",
    "mask_train = (y_train == 5) | (y_train ==7)\n",
    "X_train = X_train[mask_train]\n",
    "y_train = y_train[mask_train]\n",
    "\n",
    "mask_test = (y_test == 5) | (y_test ==7)\n",
    "X_test = X_test[mask_test]\n",
    "y_test = y_test[mask_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing Label 5 and 7 to 0 and 1 respectively\n",
    "\n",
    "y_train = np.where(y_train == 5, 0, 1)\n",
    "y_test = np.where(y_test == 5, 0, 1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing each feature vector to its unit form\n",
    "\n",
    "epsilon = 1e-10\n",
    "\n",
    "norm_train = np.linalg.norm(X_train, axis=1, keepdims=True)\n",
    "norm_train = np.where(norm_train == 0, epsilon, norm_train)\n",
    "X_train = X_train/norm_train\n",
    "\n",
    "norm_test = np.linalg.norm(X_test, axis=1, keepdims=True)\n",
    "norm_test = np.where(norm_test == 0, epsilon, norm_test)\n",
    "X_test = X_test/norm_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the current data set to get a validation set\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = sk.model_selection.train_test_split(X_train, y_train, train_size = 0.5, test_size=0.2, random_state = 1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding noise to the data set\n",
    "\n",
    "noise_mask_train = np.random.rand(len(y_train)) < 0.2\n",
    "y_train_noisy = np.copy(y_train)\n",
    "y_train_noisy[noise_mask_train] = np.where(y_train_noisy[noise_mask_train] == 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold cross-validation training function\n",
    "\n",
    "def k_fold_training(x, y, model, k):\n",
    "\n",
    "    fold_size = len(x)//k\n",
    "\n",
    "    indices = np.arange(len(x))\n",
    "\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for i in range(k):\n",
    "        testing_indices = indices[i*fold_size : (i+1)*fold_size]\n",
    "        training_indices = np.concatenate((indices[:i*fold_size], indices[(i+1)*fold_size:]))\n",
    "\n",
    "        x_training, x_testing = x[training_indices], x[testing_indices]\n",
    "        y_training, y_testing = y[training_indices], y[testing_indices]\n",
    "\n",
    "        model.fit(x_training, y_training)\n",
    "\n",
    "        accuracy = model.score(x_training, y_training)\n",
    "        scores.append(accuracy)\n",
    "        \n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train svm from a list of C or Gamma values\n",
    "\n",
    "def train_svm(c_values = None, gamma_values = None, kernel:str = 'linear'):\n",
    "\n",
    "    training_scores = []\n",
    "    validation_scores = []\n",
    "\n",
    "    if kernel == 'linear':\n",
    "        for c in c_values:\n",
    "            linear_svm = sk.svm.SVC(kernel = kernel, C = c)\n",
    "            linear_svm.fit(X_train, y_train_noisy)\n",
    "            \n",
    "            validation_scores.append(linear_svm.score(X_validation, y_validation))\n",
    "            training_scores.append(linear_svm.score(X_train, y_train))\n",
    "\n",
    "            print(f'Scores for C={c} already processed')\n",
    "\n",
    "    elif (kernel == 'gaussian') or (kernel == 'rbf'):\n",
    "        for gamma in gamma_values:\n",
    "            gaussian_svm = sk.svm.SVC(kernel = kernel, gamma = gamma)\n",
    "            gaussian_svm.fit(X_train, y_train_noisy)\n",
    "            \n",
    "            validation_scores.append(gaussian_svm.score(X_validation, y_validation))\n",
    "            training_scores.append(gaussian_svm.score(X_train, y_train))\n",
    "\n",
    "            print(f'Scores for Gamma={gamma} already processed')\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported kernel. Please use 'linear' or 'gaussian'.\")\n",
    "\n",
    "    return training_scores, validation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuction that uses \"k_fold_training\" to compare different values of C or Gamma\n",
    "\n",
    "def cross_validation(models_list):\n",
    "    models_scores = []\n",
    "    count = 0\n",
    "    for model in models_list:\n",
    "        models_scores.append(k_fold_training(X_train, y_train_noisy, model, 5))\n",
    "        count += 1\n",
    "        print(f'Model number {count} processed')\n",
    "    return models_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing C or Gamma values\n",
    "\n",
    "def test_svm(c_values = None, gamma_values = None, kernel:str = 'linear'):\n",
    "\n",
    "    X_combined = np.vstack((X_train, X_validation))\n",
    "    y_combined = np.concatenate((y_train, y_validation), axis=0)\n",
    "\n",
    "    \n",
    "    training_scores = []\n",
    "    test_scores = []\n",
    "\n",
    "    if kernel == 'linear':\n",
    "        for c in c_values:\n",
    "            linear_svm = sk.svm.SVC(kernel = kernel, C = c)\n",
    "            linear_svm.fit(X_combined, y_combined)\n",
    "\n",
    "            test_scores.append(linear_svm.score(X_test, y_test))\n",
    "            training_scores.append(linear_svm.score(X_train, y_train))\n",
    "            \n",
    "            \n",
    "\n",
    "            print(f'Scores for C={c} were processed')\n",
    "\n",
    "    elif (kernel == 'gaussian') or (kernel == 'rbf'):\n",
    "        for gamma in gamma_values:\n",
    "            gaussian_svm = sk.svm.SVC(kernel = kernel, gamma = gamma)\n",
    "            gaussian_svm.fit(X_combined, y_combined)\n",
    "            \n",
    "            test_scores.append(gaussian_svm.score(X_test, y_test))\n",
    "            training_scores.append(gaussian_svm.score(X_train, y_train))\n",
    "\n",
    "            print(f'Scores for Gamma={gamma} were processed')\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported kernel. Please use 'linear' or 'gaussian'.\")\n",
    "\n",
    "    return training_scores, test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments and Analysis\n",
    "**SVM with linear kernel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the list of C values to be tested\n",
    "\n",
    "C_values = [0.001]\n",
    "for val in range(1,10):\n",
    "    C_values.append(C_values[0]*(4**val))\n",
    "    \n",
    "print(C_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training SVMs with the list of Cs\n",
    "\n",
    "training_scores, validation_scores = train_svm(C_values, kernel = 'linear')\n",
    "print (training_scores)\n",
    "print (validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the error in training and validation sets \n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(C_values, training_scores, label='Training Score', marker='o', linestyle='-', color='blue')\n",
    "    \n",
    "plt.plot(C_values, validation_scores, label='Validation Score', marker='o', linestyle='--', color='red')\n",
    "    \n",
    "\n",
    "plt.xlabel('C Values')\n",
    "plt.ylabel('Score')\n",
    "plt.title('SVM Scores vs C Values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using K-fold training for the best 5 C values\n",
    "\n",
    "best_Cs = [0.512, 1.024, 2.048, 4.096, 8.192]\n",
    "models = []\n",
    "for c in best_Cs:\n",
    "    linear_svm = sk.svm.SVC(kernel = 'linear', C = c)\n",
    "    models.append(linear_svm)\n",
    "    \n",
    "models_scores = cross_validation(models)\n",
    "\n",
    "print(models_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the error in training and test sets\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(best_Cs, models_scores, label='Training Score', marker='o', linestyle='-', color='blue')    \n",
    "\n",
    "plt.xlabel('C Values')\n",
    "plt.ylabel('Score')\n",
    "plt.title('SVM Scores vs C Values Using K-fold Cross-Validation')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Values of C\n",
    "\n",
    "best_Cs_test = [0.512, 1.024, 2.048, 4.096, 8.192, 16.384]\n",
    "\n",
    "training_scores, test_scores = test_svm(c_values = best_Cs_test, kernel = 'linear')\n",
    "\n",
    "print (training_scores, test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(best_Cs_test, training_scores, label='Training Score', marker='o', linestyle='-', color='blue')\n",
    "plt.plot(best_Cs_test, test_scores, label='Testing Score', marker='o', linestyle='--', color='red')    \n",
    "\n",
    "\n",
    "plt.xlabel('C Values')\n",
    "plt.ylabel('Score')\n",
    "plt.title('SVM Scores vs C Values in the Full Training and Test Sets')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM with gaussian kernels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the list of C values to be tested\n",
    "\n",
    "C_values = [0.001]\n",
    "for val in range(1,10):\n",
    "    C_values.append(C_values[0]*(4**val))\n",
    "    \n",
    "print(C_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing models with different C values\n",
    "\n",
    "gaussian_svms_Cs = []\n",
    "\n",
    "for c in C_values:\n",
    "    gaussian_svm_C = sk.svm.SVC(kernel = 'rbf', C = c)\n",
    "    gaussian_svms_Cs.append(gaussian_svm_C)\n",
    "\n",
    "gaussian_svms_Cs_scores = cross_validation(gaussian_svms_Cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting C values scores results in K-fold Cross-validation for Gaussian SVMs\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(C_values, gaussian_svms_Cs_scores, label='Scores for C values', marker='o', linestyle='-', color='blue')\n",
    "\n",
    "\n",
    "plt.xlabel('C Values')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Gaussian SVM Scores vs C Values using K-fold Cross-validation')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the list of γ values to be tested\n",
    "\n",
    "γ_values = [0.001, 0.064, 1.024, 4.096]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each γ value is going to trained with the following Cs\n",
    "\n",
    "test_Cs = [1.024, 2.048, 4.096]\n",
    "gaussian_svms = []\n",
    "\n",
    "for γ in γ_values:\n",
    "    for c in test_Cs:\n",
    "        gaussian_svm = sk.svm.SVC(kernel = 'rbf', C = c, gamma = γ)\n",
    "        gaussian_svms.append(gaussian_svm)\n",
    "\n",
    "gaussian_svms_scores = cross_validation(gaussian_svms)\n",
    "\n",
    "print(gaussian_svms_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting γ and C combinations results\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(test_Cs, gaussian_svms_scores[0:3], label='Scores for γ = 0.001', marker='o', linestyle='-', color='blue')\n",
    "plt.plot(test_Cs, gaussian_svms_scores[3:6], label='Scores for γ = 0.064', marker='o', linestyle='--', color='red')\n",
    "plt.plot(test_Cs, gaussian_svms_scores[6:9], label='Scores for γ = 1.024', marker='o', linestyle=':', color='green')\n",
    "plt.plot(test_Cs, gaussian_svms_scores[9:], label='Scores for γ = 4.096', marker='o', linestyle='-.', color='purple')\n",
    "  \n",
    "\n",
    "plt.xlabel('C Values')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Gaussian SVM Scores vs C Values for each γ value using K-fold Cross-Validation')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating function to test best tuned SVMs\n",
    "\n",
    "def test_gaussian_svms(models):\n",
    "    X_combined = np.vstack((X_train, X_validation))\n",
    "    y_combined = np.concatenate((y_train, y_validation), axis=0)\n",
    "\n",
    "    \n",
    "    training_scores = []\n",
    "    test_scores = []\n",
    "\n",
    "    for model in models:\n",
    "        model.fit(X_combined, y_combined)\n",
    "        test_scores.append(model.score(X_test, y_test))\n",
    "        training_scores.append(model.score(X_train, y_train))\n",
    "        \n",
    "    return training_scores, test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing Models for testing\n",
    "\n",
    "best_Cs_gaussian = [0.256, 1.024, 4.096, 16.384]\n",
    "best_γs_gaussian = [0.256, 1.024, 4.096, 16.384]\n",
    "\n",
    "svms_0 = []\n",
    "svms_1 = []\n",
    "svms_4 = []\n",
    "svms_16 = []\n",
    "\n",
    "for c in best_Cs_gaussian:\n",
    "    if c == 0.256:\n",
    "        for γ in best_γs_gaussian:\n",
    "            gaussian_svm = sk.svm.SVC(kernel = 'rbf', C = c, gamma = γ)\n",
    "            svms_0.append(gaussian_svm)\n",
    "    \n",
    "    elif c == 1.024:\n",
    "        for γ in best_γs_gaussian:\n",
    "            gaussian_svm = sk.svm.SVC(kernel = 'rbf', C = c, gamma = γ)\n",
    "            svms_1.append(gaussian_svm)\n",
    "            \n",
    "    elif c == 4.096:\n",
    "        for γ in best_γs_gaussian:\n",
    "            gaussian_svm = sk.svm.SVC(kernel = 'rbf', C = c, gamma = γ)\n",
    "            svms_4.append(gaussian_svm)\n",
    "            \n",
    "    else:\n",
    "        for γ in best_γs_gaussian:\n",
    "            gaussian_svm = sk.svm.SVC(kernel = 'rbf', C = c, gamma = γ)\n",
    "            svms_16.append(gaussian_svm)\n",
    "\n",
    "print(len(svms_0), len(svms_1), len(svms_4), len(svms_16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svms_0_training_scores, svms_0_test_scores = test_gaussian_svms(svms_0)\n",
    "svms_1_training_scores, svms_1_test_scores = test_gaussian_svms(svms_1)\n",
    "svms_4_training_scores, svms_4_test_scores = test_gaussian_svms(svms_4)\n",
    "svms_16_training_scores, svms_16_test_scores = test_gaussian_svms(svms_16)\n",
    "\n",
    "\n",
    "print(svms_0_training_scores, svms_0_test_scores)\n",
    "print(svms_1_training_scores, svms_1_test_scores)\n",
    "print(svms_4_training_scores, svms_4_test_scores)\n",
    "print(svms_16_training_scores, svms_16_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(best_γs_gaussian, svms_0_test_scores, label='Scores for C = 0.256', marker='o', linestyle='-', color='blue')\n",
    "plt.plot(best_γs_gaussian, svms_1_test_scores, label='Scores for C = 1.024', marker='o', linestyle='--', color='red')\n",
    "plt.plot(best_γs_gaussian, svms_4_test_scores, label='Scores for C = 4.096', marker='o', linestyle=':', color='green')\n",
    "plt.plot(best_γs_gaussian, svms_16_test_scores, label='Scores for C = 16.384', marker='o', linestyle='-.', color='purple')\n",
    "  \n",
    "\n",
    "plt.xlabel('γ Values')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Gaussian SVM Scores vs γ Values for each C value in the Test Set')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(best_γs_gaussian, svms_0_training_scores, label='Scores for C = 0.256', marker='o', linestyle='-', color='blue')\n",
    "plt.plot(best_γs_gaussian, svms_1_training_scores, label='Scores for C = 1.024', marker='o', linestyle='--', color='red')\n",
    "plt.plot(best_γs_gaussian, svms_4_training_scores, label='Scores for C = 4.096', marker='o', linestyle=':', color='green')\n",
    "plt.plot(best_γs_gaussian, svms_16_training_scores, label='Scores for C = 16.384', marker='o', linestyle='-.', color='purple')\n",
    "  \n",
    "\n",
    "plt.xlabel('γ Values')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Gaussian SVM Scores vs γ Values for each C value in the Full Training set')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MLPCs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train MLPCs from a list of Alpha values\n",
    "\n",
    "def train_MLPC(alphas = None):\n",
    "\n",
    "    training_scores = []\n",
    "    validation_scores = []\n",
    "    \n",
    "    for alpha in alphas:\n",
    "        mlpc = sk.neural_network.MLPClassifier(alpha = alpha)\n",
    "        mlpc.fit(X_train, y_train_noisy)\n",
    "        \n",
    "        validation_scores.append(mlpc.score(X_validation, y_validation))\n",
    "        training_scores.append(mlpc.score(X_train, y_train_noisy))\n",
    "        \n",
    "        print(f'Scores for alpha={alpha} were processed')\n",
    "\n",
    "    return training_scores, validation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing alpha values\n",
    "\n",
    "alphas = [0.001, 0.004, 0.016, 0.064, 0.256, 1.024, 4.096, 16.384, 65.536, 262.144]\n",
    "\n",
    "training_scores, validation_scores = train_MLPC(alphas)\n",
    "\n",
    "print (training_scores, validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(alphas, validation_scores, label='Validation Score', marker='o', linestyle='-', color='blue')\n",
    "plt.plot(alphas, training_scores, label='Training Score', marker='o', linestyle='--', color='red')\n",
    "  \n",
    "\n",
    "plt.xlabel('Alpha Values')\n",
    "plt.ylabel('Score')\n",
    "plt.title('MLPCs Scores vs Alpha Values in Validation and Training sets')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating models with different activation function and hidden layer sizes\n",
    "\n",
    "functions = ['logistic', 'tanh', 'relu']\n",
    "hidden_layer_sizes = [(100,), (50,50), (25,75,25), (25,50,50,25), (25,25,25,25)]\n",
    "\n",
    "logistic_models = []\n",
    "tanh_models = []\n",
    "relu_models = []\n",
    "\n",
    "for function in functions:\n",
    "    if function == 'logistic':\n",
    "        for hidden_layer_size in hidden_layer_sizes:\n",
    "            mlpc = sk.neural_network.MLPClassifier(hidden_layer_sizes = hidden_layer_size, activation = function)\n",
    "            logistic_models.append(mlpc)\n",
    "\n",
    "    elif function == 'tanh':\n",
    "        for hidden_layer_size in hidden_layer_sizes:\n",
    "            mlpc = sk.neural_network.MLPClassifier(hidden_layer_sizes = hidden_layer_size, activation = function)\n",
    "            tanh_models.append(mlpc)\n",
    "\n",
    "    elif function == 'relu':\n",
    "        for hidden_layer_size in hidden_layer_sizes:\n",
    "            mlpc = sk.neural_network.MLPClassifier(hidden_layer_sizes = hidden_layer_size, activation = function)\n",
    "            relu_models.append(mlpc)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported activation function. Please use 'logistic', 'tanh' or 'relu'.\")\n",
    "        \n",
    "    \n",
    "print(len(logistic_models), len(tanh_models), len(relu_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training MLPCs using K-fold Cross-Validation\n",
    "\n",
    "logistic_models_scores = cross_validation(logistic_models)\n",
    "tanh_models_scores = cross_validation(tanh_models)\n",
    "relu_models_scores = cross_validation(relu_models)\n",
    "\n",
    "print(logistic_models_scores)\n",
    "print(tanh_models_scores)\n",
    "print(relu_models_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = np.arange(1, 6)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(x_axis, logistic_models_scores, marker='o', linestyle='-', label='logistic')\n",
    "plt.plot(x_axis, tanh_models_scores, marker='s', linestyle='--', label='tanh')\n",
    "plt.plot(x_axis, relu_models_scores, marker='^', linestyle=':', label='relu')\n",
    "\n",
    "plt.xlabel('Number of Hidden Layers')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('MLPCs Performance with Different Activation Functions and Hidden Layer Configurations')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating function to test MLPCs in the full training and test sets\n",
    "\n",
    "def test_mlpcs(models):\n",
    "    X_combined = np.vstack((X_train, X_validation))\n",
    "    y_combined = np.concatenate((y_train, y_validation), axis=0)\n",
    "\n",
    "    \n",
    "    training_scores = []\n",
    "    test_scores = []\n",
    "\n",
    "    for model in models:\n",
    "        model.fit(X_combined, y_combined)\n",
    "        test_scores.append(model.score(X_test, y_test))\n",
    "        training_scores.append(model.score(X_train, y_train))\n",
    "        \n",
    "    return training_scores, test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building MLPCs with different values for epocs(max_inter) and learning_rate\n",
    "\n",
    "max_interations = [50, 100, 200, 300, 500]\n",
    "learning_rates = ['constant', 'invscaling', 'adaptive']\n",
    "\n",
    "max_interations_mlpcs = []\n",
    "learning_rates_mlpcs = []\n",
    "\n",
    "for iterations in max_interations:\n",
    "    mlpc = sk.neural_network.MLPClassifier(max_iter = iterations, activation = 'relu', hidden_layer_sizes = (50,50))\n",
    "    max_interations_mlpcs.append(mlpc)\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    mlpc = sk.neural_network.MLPClassifier(solver='sgd', learning_rate = learning_rate, activation = 'relu', hidden_layer_sizes = (50,50))\n",
    "    learning_rates_mlpcs.append(mlpc)\n",
    "\n",
    "print(len(max_interations_mlpcs))\n",
    "print(len(learning_rates_mlpcs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_interations_mlpcs_training_scores, max_interations_mlpcs_test_scores = test_mlpcs(max_interations_mlpcs)\n",
    "learning_rates_mlpcs_training_scores, learning_rates_mlpcs_test_scores = test_mlpcs(learning_rates_mlpcs)\n",
    "\n",
    "print(max_interations_mlpcs_test_scores)\n",
    "print(learning_rates_mlpcs_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting reaults\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Subplot 1: Max Iterations\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(max_interations, max_interations_mlpcs_test_scores, marker='o', linestyle='-', color='blue')\n",
    "plt.xlabel('Max Iterations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('MLPC Accuracy for Different Max Iterations')\n",
    "plt.grid(True)\n",
    "\n",
    "# Subplot 2: Learning Rates\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(learning_rates, learning_rates_mlpcs_test_scores, marker='s', linestyle='--', color='red')\n",
    "plt.xlabel('Learning Rate Strategy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('MLPC Accuracy for Different Learning Rate Strategies')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring model's parameters\n",
    "\n",
    "best_mlpc = sk.neural_network.MLPClassifier(max_iter = 100, activation = 'relu', hidden_layer_sizes = (50,50), solver = 'sgd', learning_rate = 'adaptive', alpha = 0.256)\n",
    "best_gaussian_svm = sk.svm.SVC(kernel = 'rbf', C = 4.096, gamma = 4.096)\n",
    "best_linear_svm = sk.svm.SVC(kernel = 'linear', C = 4.096)\n",
    "\n",
    "best_models_list = [best_mlpc, best_gaussian_svm, best_linear_svm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data again to train in the full and not noisy set \n",
    "\n",
    "X_train, y_train = mnist_reader.load_mnist('fashion', kind='train')\n",
    "X_test, y_test = mnist_reader.load_mnist('fashion', kind='t10k')\n",
    "\n",
    "mask_train = (y_train == 5) | (y_train ==7)\n",
    "X_train = X_train[mask_train]\n",
    "y_train = y_train[mask_train]\n",
    "\n",
    "mask_test = (y_test == 5) | (y_test ==7)\n",
    "X_test = X_test[mask_test]\n",
    "y_test = y_test[mask_test]\n",
    "\n",
    "y_train = np.where(y_train == 5, 0, 1)\n",
    "y_test = np.where(y_test == 5, 0, 1)\n",
    "\n",
    "epsilon = 1e-10\n",
    "\n",
    "norm_train = np.linalg.norm(X_train, axis=1, keepdims=True)\n",
    "norm_train = np.where(norm_train == 0, epsilon, norm_train)\n",
    "X_train = X_train/norm_train\n",
    "\n",
    "norm_test = np.linalg.norm(X_test, axis=1, keepdims=True)\n",
    "norm_test = np.where(norm_test == 0, epsilon, norm_test)\n",
    "X_test = X_test/norm_test\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing best models\n",
    "\n",
    "best_models_training_scores = []\n",
    "best_models_test_scores = []\n",
    "\n",
    "for model in best_models_list:\n",
    "    model.fit(X_train, y_train)\n",
    "    best_models_test_scores.append(model.score(X_test, y_test))\n",
    "    best_models_training_scores.append(model.score(X_train, y_train))\n",
    "\n",
    "print(best_models_training_scores)\n",
    "print(best_models_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(['Best MLPC', 'Best Gaussian SVM', 'Best Linear SVM'], best_models_test_scores, marker='o', linestyle='-', color='blue', label = 'Test Set')\n",
    "plt.plot(['Best MLPC', 'Best Gaussian SVM', 'Best Linear SVM'], best_models_training_scores, marker='o', linestyle='--', color='red', label = 'Training Set')\n",
    "\n",
    "plt.xlabel('Best Models')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Scores by Models in the Full Training and Test sets')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
